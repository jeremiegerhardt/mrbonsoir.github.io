<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>A color scientist on internet</title>
    <description>Jérémie Gerhardt or mrbonsoir is sharing his experience as a color scientist. He talks about the different projects he is conducting, taking part or simply interested in as well as sharing his notes about the conferences he is attending. The topics discussed are often located at the crossroad of color science, computer vision, VR, immersive cinema... What he tries to do is to popularize color science and to avoid taking too much about him at the third person because it's weird.
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 04 Dec 2018 17:20:21 -0500</pubDate>
    <lastBuildDate>Tue, 04 Dec 2018 17:20:21 -0500</lastBuildDate>
    <generator>Jekyll v3.5.2</generator>
    
      <item>
        <title>CIC26 and HDR movie workshop</title>
        <description>&lt;h1 id=&quot;color-imaging-conference-cic-goes-to-vancouver&quot;&gt;&lt;a href=&quot;http://www.imaging.org/site/IST/IST/Conferences/CIC/CIC_Home.aspx&quot;&gt;Color Imaging Conference&lt;/a&gt; (CIC) goes to Vancouver&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Another year, another Color Imaging Conference, another location, for the 26th edition it’s Vancouver (Canada, BC).&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;enter-the-arena&quot;&gt;Enter the arena&lt;/h2&gt;
&lt;p&gt;One thing for me about this conference, that I’m attending for a couple of years, is to always stay humble as there is often the temptation to think changes are slow to come. Humble because I should remember how little I was, little I knew back in time. I don’t know much more than a few years back but I feel more confident regarding what I understand or don’t understand. And if you have color science questions, then CIC is the place to be.&lt;/p&gt;

&lt;h3 id=&quot;courses-article-and-workshop&quot;&gt;Courses, article and workshop&lt;/h3&gt;
&lt;p&gt;I had the chance to attend two short courses of the Short Course program, one course on variational Color difference (&lt;em&gt;Variational Color Image Enhancement inspired by Human Vision&lt;/em&gt; by Edoardo Provenzi) with mathematical expressions included obviously, a second one High Dynamic Range display (&lt;em&gt;The Art of Making Better Pixels: High Dynamic Range (HDR) Display Concepts and Technologies&lt;/em&gt; by &lt;a href=&quot;[linkedin.com/in/timo-kunkel-bb021917]&quot;&gt;Timo Kunkel&lt;/a&gt; from &lt;a href=&quot;https://www.dolby.com/us/en/brands/dolby-vision.html&quot;&gt;Dolby&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I presented an article we submitted my colleagues at &lt;a href=&quot;http://www.irystec.com/&quot;&gt;IRYStec&lt;/a&gt; and I a few months back, an article entitled &lt;em&gt;OLED display power model and its application to lossless perceptual algorithm&lt;/em&gt;. The basic idea behind is to say it’s important to be able to evaluate the display power consumption cost of an image on OLED display. In this era of tailoring the display to the user it’s not enough to rely on image quality metric or image quality assessment to evaluate the quality of your new algorithm. Integrating a power consumption cost is another quality factor to take into account. I was surprised and happy to find some echo of this problematic during the conference, especially in regards to HDR display on screen or [MTTBarco-link][projector]. I love conferences for that, it can show you pretty fast if you are ok or completely wrong.&lt;/p&gt;

&lt;p&gt;I also organised a workshop on HDR and Movie Production, the conference committee asked me if I could find people that were willing to talk about this topic and I jumped into that mission almost immediately.&lt;/p&gt;

&lt;h3 id=&quot;the-conference&quot;&gt;The conference&lt;/h3&gt;
&lt;p&gt;It’s basically like going back to school where you have to attend hours of short lectures on various topics. Sometimes it’s hard to stay focus, but here and there you grasp some interesting ideas, formulations and of course the authors of the articles you are reading are there too!&lt;/p&gt;

&lt;p&gt;These days I’m into perceptual display but I always keep an eye or ear on article about printing. I did my PhD in multi-spectral color reproduction, graduate in 2007, and it’s nice to see things you thought were impossible or complicated back in time that are now in use for real. Especially I think of multi-inks printing system making use of Neugebauer primaries as usable and controllable colors &lt;em&gt;Halftone structure optimization using convex programming&lt;/em&gt;, pretty cool.&lt;/p&gt;

&lt;p&gt;Below a non exhaustive of articles for this year that I found interesting: JPI-First Multi-scale Daltonization in the Gradient  Domain, Perceptually Based Restoration of backlit Images, A Study of Visible Chromatic Contrast Threshold based on Different Color Directions and Spatial frequencies, An Alternative Multi-scale Framework for Variational Perceptually-inspired Contrast Enhancement of Color Images, A Colour Appearance Model based on Jab Colour Space, Efficient Multispectral Facial Capture with Monochrome Cameras, Evaluation of HDR TVs Using Actual HDR content, Reviving Traditional Image Quality Metrics Using CNNs, Optimal Text-Background Lightness Combination for Enhancing  Visual Comfort when Using a Tablet under Different Surrounds, The Preferred Type of Tone-Curve in a Transparent OLED  Display, Assessing Color Discernibility in HDR Imaging using Adaptation Hulls, Single Anchor Sorting of Visual Appearance as an Oriented Graph and check the &lt;a href=&quot;http://www.imaging.org/site/IST/IST/Conferences/CIC/CIC_Home.aspx&quot;&gt;CIC website&lt;/a&gt; for further information.&lt;/p&gt;

&lt;h3 id=&quot;keynotes&quot;&gt;Keynotes&lt;/h3&gt;
&lt;p&gt;The evening and keynote talks given by the four speakers were particularly interesting and captivating. Keynote and evening talks are the opportunity for the speakers to tell each a story, reveal how discoveries are made, how research works sum up over time (&lt;strong&gt;A Brief Story of Superpixels&lt;/strong&gt; by Radhakrishna Achanta, how very similar problems are tackled by neighbour communities (&lt;strong&gt;Colour and Consumer Cameras: The Good, the Bad, the Ugly&lt;/strong&gt; by Michael Brown), how a research project becomes a product (&lt;strong&gt;High dynamic range on the big screen&lt;/strong&gt; by &lt;a href=&quot;[linkedin.com/in/andersballestad]&quot;&gt;Anders Ballestad&lt;/a&gt;) or how people use color science in their profession (&lt;strong&gt;Color in Narrative&lt;/strong&gt; by &lt;a href=&quot;[linkedin.com/in/andersballestad]&quot;&gt;Andrea  Chlebak&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;workshop-hdr-and-movie&quot;&gt;Workshop HDR and movie&lt;/h2&gt;
&lt;h3 id=&quot;context&quot;&gt;Context&lt;/h3&gt;
&lt;p&gt;This year I got the opportunity to organize a workshop for the CIC workshop session. Topic was very interesting to me, HDR and movie production. HDR is the new thing coming to the mainstream world of color. There is not one single definition, depending of what you do with it you will use different approaches, different words that can sometimes lead to confusion for both professionals and newbies.&lt;/p&gt;

&lt;p&gt;The movie production is particularly interesting because it brings different people together, all the way from science, engineering to art. In the last 25 years the digital wave has redefined the way we make and consume movies: multiple digital cameras, VFX, color grading, possibility to almost instantly visualise the final look of the movie after shooting a scene, different specialities, very different way to work with light, different softwares, different architectures, different representations of color, different color spaces, different displays for the consumers and now HDR.&lt;/p&gt;

&lt;p&gt;A recurring question when a new movie project is initiated is which workflow to choose? Before it was easy as all was physically printed on film, now the field of possibilities is infinite. A response to this possible recipe for disaster was &lt;a href=&quot;https://www.oscars.org/science-technology/sci-tech-projects/aces&quot;&gt;ACES&lt;/a&gt;, &lt;a href=&quot;http://opencolorio.org/&quot;&gt;OpenColorIO&lt;/a&gt; which are different and similar in the same time but help to be consistent with your workflow or color pipeline.&lt;/p&gt;

&lt;p&gt;HDR has obviously not made the production easier. As for the digital wave, not all the technologies involved in the production of movies have evolved or reached a stable state synchronously. For example HDR displays exist but the differences between professional and consumer equipments are still huge both in prices and technical specifications.&lt;/p&gt;

&lt;p&gt;That’s the starting point from this workshop. Bringing people behind the professions involved the production of moving images, let them talk about their work, their challenge, their experience in relation to HDR.&lt;/p&gt;

&lt;h3 id=&quot;looking-for-speakers&quot;&gt;Looking for speakers&lt;/h3&gt;
&lt;p&gt;I happen to know a bit about this field, the world of people crafting movie. Therefore I immediately did send a bunch of emails to my related contacts and people I didn’t know, spread my request to my color connections. I rapidly got replies, mostly positives or when the person couldn’t join but was intrigued I was left with a new name to reach out.&lt;/p&gt;

&lt;p&gt;The exact day preceding the workshop we manage to meet all of us. I knew half of the speakers thanks to previous CIC and being in Vancouver &lt;a href=&quot;[http://mrbonsoir.github.io/blog/post/2018/08/17/SIGGRAPH2018.html]&quot;&gt;last August&lt;/a&gt; for &lt;a href=&quot;https://www.siggraph.org/&quot;&gt;SigGraph&lt;/a&gt;, but for the other half it was the first time we met irl. What was suppose to be a short meeting to prepare the speakers order and verify that we don’t repeat ourselves lasted more almost two hours of engaging discussion. I could not hope for better.&lt;/p&gt;

&lt;h3 id=&quot;during-the-workshop&quot;&gt;During the workshop&lt;/h3&gt;
&lt;p&gt;The story we did want to tell is how science, engineering, art and content creation are connected along the journey to produce a movie. The panel we had was covering some of the key professions involved in that journey.&lt;/p&gt;

&lt;p&gt;Below a short resume of each speaker presentation.&lt;/p&gt;

&lt;h4 id=&quot;image-display-by-timo-kunkel-dolby-san-francisco-ca&quot;&gt;Image Display by &lt;a href=&quot;[linkedin.com/in/timo-kunkel-bb021917]&quot;&gt;Timo Kunkel&lt;/a&gt; (Dolby, San Francisco, Ca)&lt;/h4&gt;
&lt;p&gt;Timo introduced to us the science behind HDR display. I will say his part was maybe the most known to the workshop audience as many color scientists were in the room.&lt;/p&gt;

&lt;p&gt;But being a scientist in a company and therefore being involved into the making of products that will be used by not color scientists requires some additional skills, in other words to be able to explain to very different people what you are doing and what are your constraints.&lt;/p&gt;

&lt;p&gt;I was a very good introduction for the workshop, good for audience who was with us right from the beginning and not left behind. I can only recommend Timo’s short course on the topic that he regularly gives at CIC.&lt;/p&gt;

&lt;h4 id=&quot;hdr-post-production-by-chris-davies--mttbarco-vancouver-bc&quot;&gt;HDR Post-Production by &lt;a href=&quot;[linkedin.com/in/chrisdavies123]&quot;&gt;Chris Davies&lt;/a&gt;  (&lt;a href=&quot;http://www.mtt-innovation.com/&quot;&gt;MTT/Barco&lt;/a&gt;, Vancouver, BC)&lt;/h4&gt;
&lt;p&gt;Chris gave us a glimpse of the setup diversity you will encounter when you are setting a movie production workflow. You need to be pretty aware of who is doing what, how people like to work. A big challenge in HDR movie (or series) production is to have the possibility to see all along the production journey how the HDR will look.&lt;/p&gt;

&lt;p&gt;It may some sound crazy, but the HDR version could be appearing only at the end of production when the final master is released (it’s not completely crazy actually because before, physical printed movie time, there were always a delay between shooting and developing and being able to see the originals images, you had rushes - now dailies - but you were not waiting a scene to be developed to go on with the next scenes to shoot, but you were relying on the DP’s work and the lab’s trust to go on). It means that while on set the director of photography (DP) may not have an HDR display with him, most likely only the colorist or color grader will be able to grade the HDR and/or LDR version at the post-production facility. But here again professional HDR display are rare and expensive so you may have to use a consumer HDR display.&lt;/p&gt;

&lt;p&gt;That’s not all, HDR display have different sizes and available dynamic, and what a colorist need for working is maybe different than what a producer want to judge the production state. It’s not a static world.&lt;/p&gt;

&lt;h4 id=&quot;vfx-by-mario-rokicki-dneg-vancouver-bc&quot;&gt;VFX by &lt;a href=&quot;[linkedin.com/in/mario-rokicki-68769938]&quot;&gt;Mario Rokicki&lt;/a&gt; (&lt;a href=&quot;https://www.dneg.com/&quot;&gt;DNEG&lt;/a&gt;, Vancouver, BC)&lt;/h4&gt;
&lt;p&gt;Mario was kind enough to replace his colleague Sean Cooper that had too much work at DNEG London to join us.&lt;/p&gt;

&lt;p&gt;I learn a lot from Mario’s presentation (from the others as well) and here a list of key points I keep in mind regarding VFX and HDR: VFX people are working in HDR for a fair amount of time already, because VFX has to recreate everything virtually they had to deal with “how to do we encode sunlight and artificial light that have very different dynamic in the same scene?” So before HDR display they had to work with HDR content, without going too much into details you can check links below to dig more into that matter or science, but for me the fact that they are used to work in controlled light environment, pretty dark, that the image they looking at is the not final rendering is fascinating. The final look will appear when all the different contents are mixed and graded.&lt;/p&gt;

&lt;h4 id=&quot;color-grading-by-dermot-shane-independent-colorist-in-vancouver-bc&quot;&gt;Color Grading by &lt;a href=&quot;[linkedin.com/in/dermot-shane-855a39163]&quot;&gt;Dermot Shane&lt;/a&gt; (independent colorist in Vancouver, BC)&lt;/h4&gt;
&lt;p&gt;We started with science and engineering and we are slowly moving toward the art of color manipulation.&lt;/p&gt;

&lt;p&gt;In his talk introduction Dermot quoted Picasso “transform the sun into a yellow spot”. That aspect of his work was well described as well as the language. The colorist/color grader is another key role in the production workflow, he or she has is the last link between the movie director and the final look of the project, he/she needs to translate the DP visions into the available technology. Vocabulary is important and Dermot illustrated his presentation with a series of short video sequences where he explained what was tried to be achieved in those short videos. Understanding how a movie scene is constructed in term of lighting is obviously important. In his last example Dermot did show us a scene and the corresponding making off, a very dark scene from Harry Potter - dark in the sense of low light - that actually required a lot of light on stage. It can be counterintuitive but it tells us a lot of on how movie maker are capturing and manipulating light in its whole dynamic.&lt;/p&gt;

&lt;h4 id=&quot;movie-grammar-for-hdr--by-shane-mario-ruggieri-dolby-in--sunnyvale-ca&quot;&gt;Movie grammar for HDR  by &lt;a href=&quot;[linkedin.com/in/shanemarioruggieri]&quot;&gt;Shane Mario Ruggieri&lt;/a&gt; (&lt;a href=&quot;https://www.dolby.com/us/en/brands/dolby-vision.html&quot;&gt;Dolby&lt;/a&gt; in  Sunnyvale, CA)&lt;/h4&gt;
&lt;p&gt;We have come full circle with Mario concluding each speaker talk. Mario is a colleague of Timo that started the workshop. He has many roles and experiences from Sr. Production Engineer, Producer and Colorist part of Dolby Laboratories’ Advanced Technology Group since 2010. One of his tasks is to go behind creating HDR test chart.&lt;/p&gt;

&lt;p&gt;Once again language, grammar is important such as understanding how people make movie, how they tell stories with images. It’s a pretty unique skill to be able to achieve that task, to talk to scientists and artists. Therefore during his talk Shane did present a short movie where he could link words, actions, lightings possibilities, emotions, how we react to change of illumination, basically story telling with HDR in mind.  Once thing you want for sure is to avoid the &lt;em&gt;3D&lt;/em&gt; effect, to be interesting HDR has to go away from the “I have more light budget”.&lt;/p&gt;

&lt;h3 id=&quot;panel-discussion&quot;&gt;Panel discussion&lt;/h3&gt;
&lt;p&gt;Good thing is HDR has evolved a lot in the past years but there are still a lot to do.&lt;/p&gt;

&lt;p&gt;There is a need for better transforms based in science for previewing how HDR look.&lt;/p&gt;

&lt;p&gt;There is a need for bigger, brighter HDR display, but switching too rapidly is dangerous too, for e.g. in VFX the artists work with LDR display and are used to be in muted environment.&lt;/p&gt;

&lt;p&gt;And again language, all the people involved in the production of a movie are dealing with the same material, light, but each of them has a different vocabulary, goal, mission to handle it. This aspect of movie production hasn’t changed and still movie are produced.&lt;/p&gt;

&lt;p&gt;Finally a great pleasure for me to have been able to bring all these talented people in the same room. So a big thank-you to the speakers for sharing their experiences.&lt;/p&gt;

&lt;h2 id=&quot;links-to-continue-on-this-topic&quot;&gt;Links to continue on this topic&lt;/h2&gt;
&lt;p&gt;A few links if you want to know more on the movie production workflow:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://postperspective.com/colorist-weighs-new-world-hdr/&quot;&gt;postperspective&lt;/a&gt; website&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;[https://postperspective.com/colorist-weighs-new-world-hdr/]&quot;&gt;A colorist interview&lt;/a&gt; on &lt;em&gt;the new world&lt;/em&gt; of HDR&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://opencolorio.org/&quot;&gt;OpenColorIO&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.oscars.org/science-technology/sci-tech-projects/aces&quot;&gt;ACES&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 04 Dec 2018 15:15:15 -0500</pubDate>
        <link>http://localhost:4000/blog/post/2018/12/04/CIC26-and-HDR-movie-workshop.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2018/12/04/CIC26-and-HDR-movie-workshop.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>SIGGRAPH2018</title>
        <description>&lt;h2 id=&quot;first-siggraph&quot;&gt;First SIGGRAPH&lt;/h2&gt;
&lt;p&gt;I heard about it so often and this time I made it. About 20000 persons attending the event, this time in Vancouver. A scientific conference with many sessions in parallel so you can’t follow them all, impossible. A huge expo where companies are presenting their products, movie and VFX studios are recruiting. The opportunities for many people to exchange knowledge and information.&lt;/p&gt;

&lt;p&gt;It was my first &lt;a href=&quot;https://www.siggraph.org/&quot;&gt;SIGGRAPH&lt;/a&gt; and I knew I could not attend all the events and talks but I tried my best: attending a few birds of a feather sessions, demo sessions, talking with the different actors of those fields, trying to connect the dots, envisaging what are the trends this year (VR, ML, HDR, opensource..)&lt;/p&gt;

&lt;h2 id=&quot;birds-of-feathers-bofs&quot;&gt;Birds of Feathers (BoFs)&lt;/h2&gt;
&lt;p&gt;These sessions are usually the occasion to get status updates on cross-platforms projects, workflows followed by different movie and VFX studios for example. The one on &lt;a href=&quot;http://www.oscars.org/science-technology/sci-tech-projects/aces&quot;&gt;ACES&lt;/a&gt; and &lt;a href=&quot;http://opencolorio.org/&quot;&gt;OpenColorIO&lt;/a&gt; were particularly interesting to me as they contain a lot of applied color related challenges.&lt;/p&gt;

&lt;h2 id=&quot;more-open-source-projects-in-movie-production&quot;&gt;More Open Source projects in movie production&lt;/h2&gt;
&lt;p&gt;I follow ACES and OpenColorIO for years, they seem similar sometimes but not always. It’s a mix of guidelines, open standards that are evolving permanently.&lt;/p&gt;

&lt;p&gt;The switch to almost full digital workflow for the production of movies did shake up the existing movie production workflow. The resolution and quality in digital workflow is now completely equivalent as the analog workflow. It doesn’t mean that the visual experience is equivalent but it requires sometimes different way of thinking. A big challenge is the inter-operability between softwares without loosing information (i.e. color, bit resolution…) when going from one software to the other, typically when different departments are working on the same movie (the image acquisition and VFX to color grading for example) or in animation how different objects of a scene can be manipulated with different tools.&lt;/p&gt;

&lt;p&gt;This year I could observe a push from different companies (&lt;a href=&quot;https://www.autodesk.ca&quot;&gt;Autodesk&lt;/a&gt;), studios, associations, organisations (&lt;a href=&quot;http://www.oscars.org/science-technology/sci-tech-projects/aces&quot;&gt;The Academy&lt;/a&gt;) to go open source and join the &lt;a href=&quot;https://www.linuxfoundation.org/&quot;&gt;Linux Foundation&lt;/a&gt;. The tools, workflows in movie production/video game productions are highly customisable to be able to communicate between products. That’s why there are so many developers in studios. One problem is when those people are changing companies, their work or knowledge is sometimes lost… So the opensource move is a good move, if you leave your work you can still contribute to the project you were involved, or if you join a new team you may come with already some knowledge about the tools used in the studio.&lt;/p&gt;

&lt;h2 id=&quot;strong-french-presence&quot;&gt;Strong French presence&lt;/h2&gt;
&lt;p&gt;I’m not particularly patriotic but I have a bit a pride when I see a bunch of French companies making it on international level, childish I know. The expo hall had a fairly big French delegation, interesting is you don’t need to be a large company of enormous studio (regarding the number of employees) to play on a worldwide level, see &lt;a href=&quot;http://www.mikrosimage.com/&quot;&gt;mikros&lt;/a&gt;, &lt;a href=&quot;http://guerillarender.com/&quot;&gt;Guerilla Render&lt;/a&gt;, &lt;a href=&quot;http://primcode.com/&quot;&gt;primcode&lt;/a&gt;…&lt;/p&gt;

&lt;h2 id=&quot;vr-everywhere&quot;&gt;VR everywhere&lt;/h2&gt;
&lt;p&gt;A bit of zombieland around my hotel on Hasting East street, lovely and unexpected, at the convention center too. I explain. Many companies are demoing their product, many of them being VR headset experience, so you will witness many people standing with their arms searching something as if they were walking into the darkness and someone around trying to catch them if they were falling.&lt;/p&gt;

&lt;p&gt;Interesting because you can try many headsets, evaluate the ongoing work, research on improving the experience, reducing motion sickness, making the experience more realistic. Some will add eye-trackers to render content according to where the user is looking at as tracking the head movement isn’t enough. What makes the experience really immersive is the impression to have an extended field of view as opposed to &lt;em&gt;just&lt;/em&gt; look into binoculars. I had the chance to try headset from &lt;a href=&quot;https://zerolight.com/&quot;&gt;Zerolight-STARVR&lt;/a&gt; who was really amazing with &lt;em&gt;natural field of view&lt;/em&gt; as they call it.&lt;/p&gt;

&lt;p&gt;A big challenge with VR headset is not only the field of view or sometimes motion sickness but the control of the display lighting. What makes an intensity display level comfortable for the viewer? What level of details or resolution is acceptable, what is the combination of all these parameters to make the experience truly immersive? We all are working on it and &lt;a href=&quot;http://www.irystec.com/&quot;&gt;us&lt;/a&gt; too.&lt;/p&gt;

&lt;h2 id=&quot;machine-learning-ml&quot;&gt;Machine Learning (ML)&lt;/h2&gt;
&lt;p&gt;Something I could hear, the use of ML to help users finding the best parameters in their workflows. Working on a movie implies the fusion of many different sources, many different people and sometimes a tiny mistake on assuming this color space or this white point or this LUT at any point of the production workflow will completely fucked up your final look. And you don’t want that despite using the right softwares or softwares suit (&lt;a href=&quot;https://www.filmlight.ltd.uk/&quot;&gt;FilmLight&lt;/a&gt;, &lt;a href=&quot;https://www.blackmagicdesign.com/products/davinciresolve/&quot;&gt;davinci resolve&lt;/a&gt;…). That’s why &lt;a href=&quot;http://www.oscars.org/science-technology/sci-tech-projects/aces&quot;&gt;ACES&lt;/a&gt; and &lt;a href=&quot;http://opencolorio.org/&quot;&gt;OpenColorIO&lt;/a&gt; are important too. Depending of your workflow setup you will be able to control or overview all your pipeline at any time, having someone responsible of the pipeline or simply don’t have the time or money for that, in that case having a virtual assistant (based on ML, AI) can be the solution (with a price of course).&lt;/p&gt;

&lt;h2 id=&quot;more-stuffs&quot;&gt;More stuffs&lt;/h2&gt;
&lt;p&gt;I wish I could talk more about farm rendering, computation in the clouds, hdr, color grading, demos I have attended (e.g. demo on making animation with &lt;a href=&quot;https://unity3d.com/&quot;&gt;Unity&lt;/a&gt; and &lt;a href=&quot;https://www.autodesk.ca/en/products/maya/overview&quot;&gt;Maya&lt;/a&gt;). I just hope I could attend next year event! For sure a great place to witness basic and applied science meeting live.&lt;/p&gt;

</description>
        <pubDate>Fri, 17 Aug 2018 16:21:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2018/08/17/SIGGRAPH2018.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2018/08/17/SIGGRAPH2018.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Reproducible research</title>
        <description>&lt;p&gt;To continue on sharing my longest work experience in a startup - &lt;a href=&quot;http://www.irystec.com/&quot;&gt;IRYStec&lt;/a&gt; in Montreal - I will talk today about &lt;a href=&quot;https://en.wikipedia.org/wiki/Reproducibility&quot;&gt;reproducible research&lt;/a&gt; and more how to concretely achieve it.&lt;/p&gt;

&lt;h2 id=&quot;the-struggle-continues&quot;&gt;The struggle continues&lt;/h2&gt;

&lt;p&gt;First of all I’m lucky enough to be able to continue research activities since I finish my Phd in 2007, I’m employed as senior color scientist after all, meaning not only I have research projects but I can also communicate some aspects of it. In other words I’m allowed submit parts of my work to conferences and therefore make some of our research available to the people.&lt;/p&gt;

&lt;h2 id=&quot;making-tools&quot;&gt;Making tools&lt;/h2&gt;

&lt;p&gt;Doing research you spent a lot of time developing tools, frameworks to ease the conduct of experiments and to facilitate the reproduction of those experiments. What you certainly don’t want is that the same command to run a function or a script gives you each time different results.&lt;/p&gt;

&lt;p&gt;Working in a startup where all the teams are in the same office gives you the chance to be closer to your colleagues and their specialities. My colleagues developers for whom the challenge - one of them - is to translate the work of the research team, advanced prototypes into a product. This means re-building something to make it stable and reproducible.&lt;/p&gt;

&lt;h2 id=&quot;the-magic&quot;&gt;The magic&lt;/h2&gt;

&lt;p&gt;Changing habits is difficult but learning new tools is fun too, hard at the beginning but so rewarding after you improved something. The motivation to try and/or learn something new can comes from different sources. Often it’s driven by laziness, you know that this framework, this set of guidelines will make you gain time, so you learn it.&lt;/p&gt;

&lt;p&gt;I’m using git for a while but until recently in a very simple fashion. Working in a team made me realized the power of git, the various configurations I met made me see that, working alone on a project versus working in collaboration to others.&lt;/p&gt;

&lt;h2 id=&quot;more-hocus-pocus-and-wizzardy&quot;&gt;More hocus pocus and wizzardy&lt;/h2&gt;

&lt;p&gt;More magic happen when I went digging into &lt;a href=&quot;https://en.wikipedia.org/wiki/Docker_(software)&quot;&gt;docker&lt;/a&gt;. I was looking for a better solution than &lt;a href=&quot;http://docs.python-guide.org/en/latest/dev/virtualenvs/&quot;&gt;Python virtual environment&lt;/a&gt; which is already a huge step into improving your Python development skills, controlling on your working environment. I’m usually prototyping with the head in &lt;a href=&quot;http://jupyter.org/&quot;&gt;Jupyter notebook&lt;/a&gt;, once again working alone it’s fine, but as soon as you want to share you work with someone else the trouble starts as we almost always don’t have the same working environment (linux, mac, windows…). We may use the same Python version but not exactly with the same list of modules or external softwares installed on your machine. A long list of little differences that can compromise the reproducibility of your work.&lt;/p&gt;

&lt;p&gt;After some googling, I came back to my colleagues and start to question them to help me to setup a reproducible working environment for Python and a jupyter notebook. I thought of jupyter notebook server, but being not completely convinced we looked into the docker direction. I’m still amazed with the results. We came a up a solution inspired from existing solutions that suits me: create a docker with Ubuntu, with the necessary Python modules, the possibility to run a Jupyter notebook server in the docker while accessing local notebooks and data. In other words you control you data as usual, but the working environment is totally transportable, as today I can work at the office on my desktop computer running Ubuntu or being outside on my Mac and being sure I have the same working environment everywhere.&lt;/p&gt;

&lt;h2 id=&quot;why-is-it-cool-for-research&quot;&gt;Why is it cool for research?&lt;/h2&gt;

&lt;p&gt;It’s a topic - reproducible research - more visible in research publications. Many of us are running experimentations on a computer, but each of us uses slightly different setups. It’s extremely frustrating to read the work of another researcher that is public, article available, data available, code totally or partially available, you run some code and you don’t obtain the same results when you are lucky to be able to run something.&lt;/p&gt;

&lt;p&gt;I can only see benefit in sharing - when it’s possible - also the tools used to obtain you results, not only the equations and results, the code and working environment too. In the same spirit I often enjoy visiting conferences which are covering slightly different domains to my own expertise. Sometimes the way a problem is solved will give you a hint on how to solve another problem. On those beautiful ideas I stop.&lt;/p&gt;

&lt;h2 id=&quot;petit-à-petit-loiseau-fait-son-nid&quot;&gt;Petit à petit l’oiseau fait son nid&lt;/h2&gt;

&lt;p&gt;Therefore I created this new repository I called &lt;a href=&quot;https://github.com/mrbonsoir/researchlab/&quot;&gt;researchlab&lt;/a&gt; (to be exact I modified an existing solution with the invaluable help and knowledge of my colleagues) where you can find information to build a docker image containing Python and jupyter notebook, together with bash script to use it. Continuing on that incredible achievement - for me - I re-modified this project to setup a digital atelier for my side projects. Very cool.&lt;/p&gt;

</description>
        <pubDate>Tue, 08 May 2018 16:21:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2018/05/08/Reproducible-research.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2018/05/08/Reproducible-research.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>One Year in a startup</title>
        <description>&lt;h2 id=&quot;a-year-already&quot;&gt;A year already&lt;/h2&gt;

&lt;p&gt;One year in the same company, two countries and many more new stuffs learned during that time.&lt;/p&gt;

&lt;p&gt;Let’s re-introduce myself. I’m a color scientist and I have worked on various projects in the past 10 years, all of them having in common a signal to be processed, often the signal being an image visible by a human observer.&lt;/p&gt;

&lt;p&gt;I’m doing now r&amp;amp;d in a startup in Montréal, working on image quality and perceptual display. Being in a startup with experienced colleagues is a pretty good setup.&lt;/p&gt;

&lt;p&gt;On one side learning and improving an algorithm to improve image quality. The research point of view allows you to optimize, implement this algorithm. The goals are image quality and feasibility. You take your Matlab, your python, your pen and paper, process images, compute differences, eventually run psychophysic experiments, anything that can be done not in real time.&lt;/p&gt;

&lt;p&gt;On the other side, as I said I’m working in as startup (&lt;a href=&quot;http://www.irystec.com/&quot;&gt;IRYStec&lt;/a&gt;) and the challenge is to be able to quickly port a research project into production. Running your algorithm on your desktop computer is different than running it on a portable device in real time with more than one display technology… But that’s where it’s interesting too and that’s where you/I learn new stuffs.&lt;/p&gt;

&lt;h2 id=&quot;keep-learning&quot;&gt;Keep learning&lt;/h2&gt;

&lt;p&gt;Interesting because you have to learn new tools, here programming tools like openGL in order to program shader, re-think your algorithm for applying it in real time on a different hardware. And usually it’s less powerful than what you were used too… But it can help because it forces you to tackle your problem with another angle. You started with image processing, human vision system, perceptual display, JND and you finish with computer vision, electronic, hdr and shader programming.&lt;/p&gt;

&lt;p&gt;The evaluation of your work is different too. You don’t validate your solution with the same criteria if your are in research or in production. It seems obvious but your algorithm - if it has something to do with human vision - has quality cost (you want your image to be better or the original quality preserved such that perceptually the difference isn’t noticeable) and processing cost (if applying your new algorithm improves the visual quality but can only be ran at 10 fps it’s also a quality issue).&lt;/p&gt;

&lt;p&gt;Luckily you are not supposed to do everything, you and your colleagues have different skills, but you both should have crossover knowledge. Your supervisor should be able to fill the gap at the beginning or it’s like having two groups speaking a different language trying to solve the same problem hoping that magically they will understand each other. Understanding a minimum of how your office neighbor is working is more than relevant. It’s like your are on a fast car trying to catch a train and are looking for the jump that will help your to land on this moving train (this a beautiful picture of research and production).&lt;/p&gt;

&lt;h2 id=&quot;kafkaesque-bonus-track-oled-vs-lcd&quot;&gt;Kafkaesque bonus track, OLED vs LCD&lt;/h2&gt;

&lt;p&gt;OLED is trying to take over the world dominated by LCD technology. The big name are slowly switching to this technology. You can be almost sure that the middle names will follow until a new display technology arrives on the market. Take that planned obsolescence.&lt;/p&gt;

&lt;p&gt;What is confusing for consumers and researchers/engineers like me is the fact that two distinct TV displays can reach the same quality standard. Standard defined by experts, people from the industry. Standard saying these TVs have the same quality, also they produce different visual experience…&lt;/p&gt;

&lt;p&gt;It’s safe to say that if your setup is dark, no parasite lights around your TV, you may choose an OLED display to exploit the good &lt;em&gt;behavior&lt;/em&gt; of OLED in dark level, a pixel to 0 don’t produce light.&lt;/p&gt;

&lt;p&gt;It’s also safe to say that if your setup is quite bright, you will need a pretty bright display to compensate the ambient parasite light, therefore you may choose an LCD TV display. LCD are usually brighter than OLED, but it’s important too to distinguish between OLED TV display and portable OLED display…&lt;/p&gt;

&lt;p&gt;And we talk later about HDR which is pretty fun too. Especially when a device is said to be &lt;em&gt;HDR ready&lt;/em&gt; and is actually not an HDR display but a device that can perform &lt;em&gt;video tone mapping&lt;/em&gt; which is the action of mapping HDR content to a regular (or LDR) display. Here too there are plethora of HDR encoding :-)&lt;/p&gt;

</description>
        <pubDate>Tue, 06 Feb 2018 09:21:06 -0500</pubDate>
        <link>http://localhost:4000/blog/post/2018/02/06/One-year-in-a-startup.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2018/02/06/One-year-in-a-startup.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>CIC 25 in Lillehammer</title>
        <description>&lt;p&gt;This year have seen the 25th edition of the &lt;a href=&quot;https://www.imaging.org/site/IST/Conferences/Color_and_Imaging/IST/Conferences/CIC/CIC_Home.aspx&quot;&gt;Color Imaging Conference (CIC)&lt;/a&gt;) taking place in Lillehammer (Norway) after &lt;a href=&quot;http://mrbonsoir.github.io/blog/post/2016/11/12/CIC-in-San_Diego.html&quot;&gt;San Diego&lt;/a&gt; (California).&lt;/p&gt;

&lt;p&gt;This time again I could be part of the committee as a co-chairman for the &lt;strong&gt;Short Course&lt;/strong&gt; session. Session where conference attendees or not attendees can register and take courses (you need to pay for each course you want to follow) on carefully selected topics. Basis of color science courses are of course available but also several advance courses on different topics given by field specialists (e.g courses on hdr, color differences and other colorful themes). The instructors are usually coming from academia and/or industry - when their industry allows them to talk - and each course is first submitted, reviewed and/or not accepted.&lt;/p&gt;

&lt;h3 id=&quot;back-to-norway&quot;&gt;Back to Norway&lt;/h3&gt;

&lt;p&gt;I have been visiting Norway regularly after I left Gjovik in 2008 and its &lt;a href=&quot;https://www.ntnu.edu/colourlab&quot;&gt;colorlab&lt;/a&gt; (a few km South of Lillehammer) where I did my PhD on multispectral color reproduction. It was something to come back in the lab, seeing old colleagues, seeing that the color lab did grow nicely and was heavily represented at the conference.&lt;/p&gt;

&lt;h3 id=&quot;general-overview&quot;&gt;General overview&lt;/h3&gt;

&lt;p&gt;Over the years you appreciate the conference with different perspectives. Now that I know a bit more about my field - color science - I can witness that each sub-field is evolving slowly, appreciate tiny changes, observe the increase of general knowledge. There is always something.&lt;/p&gt;

&lt;h3 id=&quot;human-perception-and-colour-constancy&quot;&gt;Human perception and colour constancy&lt;/h3&gt;

&lt;p&gt;Keynotes, first and second have been pretty interesting. The first one given by Apple - almost did coincide with the Apple event in California - was impressive and disturbing in the same time. Impressive because of the amount of advanced technology they are able to squeeze into a smartphone. Disturbing by the non research dissemination they are doing. They have a great team of researchers and engineers but all the knowledge stay at work, not sure it will make the people smarter at the end. I’m sure they are not the only company doing that, but they are so big the result of such behavior has an impact.&lt;/p&gt;

&lt;p&gt;Second keynote was entitled &lt;em&gt;Twenty-five Years of Colour Constancy&lt;/em&gt; given by &lt;a href=&quot;http://www.ncl.ac.uk/ion/staff/profile/anyahurlbert.html#background&quot;&gt;Anya Hurlbert from Newcastle University (UK)&lt;/a&gt;. Needless to say it was pretty entertaining, a the typical presentation that make you feel smarter at the end. &lt;a href=&quot;https://en.wikipedia.org/wiki/Color_constancy&quot;&gt;Colour constancy&lt;/a&gt; is a fascinating phenomena which can be understood as white balancing done by the brain. We have not all the same automatic white balance algorithm embedded with us, this resulting
endless discussion on object color, remember the blue-black/yellow-white dress-gate a few month ago?&lt;/p&gt;

&lt;h3 id=&quot;subjective-evaluation-image-metrics-and-database&quot;&gt;Subjective evaluation, image metrics and database&lt;/h3&gt;

&lt;p&gt;There are so many metrics it’s becoming difficult to follow on that topic. To have a idea have a look at the &lt;a href=&quot;http://www.ponomarenko.info/tid2013.htm&quot;&gt;Tampere Image Database TID203&lt;/a&gt;. Each of them is trying to mimic how human perception is working, allowing to evaluate image difference, predict how image quality will be perceived when a new algorithm is applied to images.&lt;/p&gt;

&lt;p&gt;A solution is to follow an experimental workflow which integrate feedback from standard real observers. A panel of test persons is asked to look at images, original and modified and to compare them. Notion of &lt;a href=&quot;https://en.wikipedia.org/wiki/Just-noticeable_difference&quot;&gt;just noticeable difference (JND)&lt;/a&gt; is of course very important here. In that case subjective evaluation is often chosen, but here are well they is plenty of existing experimental workflows to choose from.&lt;/p&gt;

&lt;h3 id=&quot;human-vs-bird-viewing-system&quot;&gt;Human vs bird viewing system&lt;/h3&gt;

&lt;p&gt;Going to the same conference each year sometimes shows you how alone are  researchers. Most of them are spending their life on one topic and they become hyper specialist. A conference is the occasion for them to leave their laboratory, office and to share their discoveries (in that case other color scientists).&lt;/p&gt;

&lt;p&gt;A peculiar article tilted &lt;em&gt;Super Vision Model: What’s Peking Robin Seeing?&lt;/em&gt; by researcher Hiroaki Kotera from Kotera Imaging Laboratory, Chiba, Japan was pretty cool. This research work looked at birds (the Peking Robin) and their visual system: they are tetra-chromate &lt;em&gt;RGBU&lt;/em&gt; when we are tri-chromate &lt;em&gt;RGB&lt;/em&gt;. Question being how these animals see colors? &lt;em&gt;Four sensors and tiny brain Vs us three sensors and bigger brain that allows to post-process the signal and compensate for a lower captor resolution&lt;/em&gt; or how nature optimizes living organism for dedicated tasks within an ecosystem. The non-visible sensor allowing this bird to evaluate more precisely the quality of food (e.g. is this fruit already rotten or not?). A parallel can be done with computational photography when the algorithms and post-processing present in smartphone can compensate for their lower quality hardware (to some extend) compare to high-end dslr.&lt;/p&gt;

&lt;h3 id=&quot;workshop-session&quot;&gt;Workshop session&lt;/h3&gt;

&lt;p&gt;I could attend only two of the three parallel workshop sessions. interesting on many points. Both workshops &lt;em&gt;W2: VISUAL PERCEPTION AND EMERGING TECHNOLOGIES IN CINEMA: PERSPECTIVES FROM ACADEMIA AND THE INDUSTRY&lt;/em&gt; and &lt;em&gt;W3: CULTURAL HERITAGE DIGITIZATION: CHALLENGES AND OPPORTUNITIES&lt;/em&gt; shared cutting edge used of technologies. More important they allow to have discussions between professionals from different entities without revealing company secrets.&lt;/p&gt;

&lt;h3 id=&quot;la-suite&quot;&gt;La suite&lt;/h3&gt;

&lt;p&gt;Hope to be part of next year edition in 2018. For now the next destination hasn’t been revealed, but according to recent tradition it should return to North America.&lt;/p&gt;

</description>
        <pubDate>Fri, 15 Sep 2017 20:21:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2017/09/15/CIC-Lillehammer.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2017/09/15/CIC-Lillehammer.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Notes on NLP and color</title>
        <description>&lt;p&gt;This post is a never ending story and a follow up on a previous article on &lt;a href=&quot;http://mrbonsoir.github.io/blog/post/2014/05/28/Graph-en-stock.html&quot;&gt;graph and NoSql&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;how-to-organize-my-research&quot;&gt;How to organize my research?&lt;/h3&gt;
&lt;p&gt;I started to work on a few projects the last two months, projects involving color science, color space, finding the right JNDs (or Just Noticeable Differences) for our algorithms, display modeling and more.&lt;/p&gt;

&lt;p&gt;As usual with this type of R&amp;amp;D projects there is a bibliography stage in order to figure out what you understand about the topic and what have the people done about it. Pretty fast you are making cross references and identify which papers, authors, keywords are important to that topic. If you want to really understand and go further you need to read/re-do all of this work.&lt;/p&gt;

&lt;h3 id=&quot;déjà-view&quot;&gt;Déjà view&lt;/h3&gt;
&lt;p&gt;One more time when I’m facing this working situation where I’m missing a tool to represent the interactions between those publications. If you write a research article you pretty much have the connections between the works of others in your head, basically who is referring to whom, you tell your story while adding references in your writing instead of drawing a genealogy research tree. Having in my hand a tool to kind of visualize those connections will be nice as a support, something between illustration and text.&lt;/p&gt;

&lt;h3 id=&quot;the-database&quot;&gt;The database&lt;/h3&gt;
&lt;p&gt;A research article has always its sources listed with it, each source having as well links to other articles. The question I’m often facing is how do I build my DB - which I already have, e.g. &lt;strong&gt;bib&lt;/strong&gt; file containing a list of references with &lt;em&gt;year&lt;/em&gt;, &lt;em&gt;authors&lt;/em&gt;, &lt;em&gt;reference title&lt;/em&gt; and more - in order to request information I can’t directly see but only briefly grasp?&lt;/p&gt;

&lt;h3 id=&quot;the-requests-and-the-wishes&quot;&gt;The requests and the wishes&lt;/h3&gt;
&lt;p&gt;Regarding the requests I know what are the question I would like to have the answer from my DB:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;what is the degree of relationship between author A and author B.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In term of Natural Language Processing (NLP) I would be also really interesting to compare words used by different group of researchers. Ideally I could like to create:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;graphs of connections between researchers based on their publications&lt;/li&gt;
  &lt;li&gt;graphs of keywords to visualize how fields and sub-fields are represented.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 10 Apr 2017 14:21:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2017/04/10/Notes-on-NLP-and-color.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2017/04/10/Notes-on-NLP-and-color.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>CIC 2016 in San Diego</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://www.imaging.org/site/IST/Conferences/Color_and_Imaging/IST/Conferences/CIC/CIC_Home.aspx&quot;&gt;Color Imaging Conference&lt;/a&gt; just ended. This year it took place in San Diego CA and once again a good event! For the fourth time in a row I did join this event as a co-chair, this time for the &lt;strong&gt;short course&lt;/strong&gt; session that usually takes place the whole day before the conference program.&lt;/p&gt;

&lt;h3 id=&quot;what-did-we-learn-this-year&quot;&gt;What did we learn this year?&lt;/h3&gt;

&lt;p&gt;After attending many of this conference editions it’s easy to think that the field doesn’t move fast enough. But it’s not true, it’s going forward and it’s always a good exercise to de-construct or re-build the reasoning behind the presentations given by the different researchers and scientists.&lt;/p&gt;

&lt;h3 id=&quot;wide-gamut-vs-hdr-display&quot;&gt;Wide gamut vs hdr display&lt;/h3&gt;

&lt;p&gt;What I keep in my head this year are the discussions about display. I could join a particularly interesting course about &lt;strong&gt;color grading&lt;/strong&gt;, &lt;strong&gt;post-production&lt;/strong&gt; where attention was put on the following point: what are we talking about when we talk about &lt;strong&gt;wide gamut&lt;/strong&gt; and &lt;strong&gt;hdr display&lt;/strong&gt;? The question actually came during the course.&lt;/p&gt;

&lt;p&gt;The movie industry and especially the production and post-production parts offer a live laboratory to observe where the applied color science is going. It’s a battle where people try to bring the most realistic experience to the spectators in cinema theater or at home.&lt;/p&gt;

&lt;p&gt;The workflow developed for each movie is often on the verge of what is existing as often a unified commercial solution is not there yet, so you have to build it: one want to have more color and extend the gamut, one want to have an higher fps, another want to have a bigger dynamic of intensity, you see the challenges here.&lt;/p&gt;

&lt;h3 id=&quot;personalized-display&quot;&gt;Personalized display&lt;/h3&gt;

&lt;p&gt;Display is obviously a very hot topic of these days. The understanding we have now of how the human visual system works, human color perception, the possibility to evaluate one’s vision ability depending of your age, gender and many more factors is a golden mine.&lt;/p&gt;

&lt;p&gt;This means that &lt;strong&gt;each display content can be optimized&lt;/strong&gt; to each viewer. In some configuration it can be super important. If you take the car industry where displays are more and more present to help the driver, optimizing the displayed images such that the driver can get the most important information is essential for its safety and the people around.&lt;/p&gt;

</description>
        <pubDate>Fri, 11 Nov 2016 19:01:06 -0500</pubDate>
        <link>http://localhost:4000/blog/post/2016/11/11/CIC-in-San_Diego.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2016/11/11/CIC-in-San_Diego.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Working with noise control</title>
        <description>&lt;p&gt;I like to write. I have to write often for work but I also enjoy to write for myself about &lt;a href=&quot;http://mrbonsoir.blogspot.com&quot;&gt;stuffs&lt;/a&gt; not specifically related to work. Writing anything requires concentration and sometimes it’s easy to search for distraction instead of clearing your head, focusing on the task to be done and doing it. Actually writing or reading both require a lot of concentration and over the years I develop a strategy when it’s time to think, write or read. Yes sometimes I think.&lt;/p&gt;

&lt;p&gt;The answer is music, or noise or even more precisely auto-generative music or self-generative noise. I don’t remember how I ended up on &lt;a href=&quot;http://www.noisli.com/&quot;&gt;noisli&lt;/a&gt; but since this discovery I intensively use this website/app to shape the sound atmosphere around me. You can mix together different background sounds, this is the idea, to create a noise mix if not musical that will keep you in your bubble, to surround you in a way that elements from the outside will not disturb you.&lt;/p&gt;

&lt;p&gt;Recreating the sound from the train or while being in an airplane works for me. I wish Miles Davis album &lt;a href=&quot;https://en.wikipedia.org/wiki/In_a_Silent_Way&quot;&gt;Silent Way&lt;/a&gt; could be played forever, with &lt;a href=&quot;http://www.noisli.com/&quot;&gt;noisli&lt;/a&gt; I can simulate the noise from a train ride. But the delicate sound from an FM frequency without voices is so relaxing to me.&lt;/p&gt;

&lt;p&gt;Now I’m not only using this app for working or to put myself into the quest for concentration, no. In winter I like to hear the sound of the fire crackling together with a light wind, it’s warming up my flat and my feet. The same in summer when it’s too warm, a bit of wind, a bit of lighting noise and/or the sound of light waves on the beach has a strong effect.&lt;/p&gt;

&lt;p&gt;Coming from the field of color science, computer vision, VR stuffs I find this kind of app extremely simple and super immersive. Video game designers didn’t wait for me to incorporate sound into their games to increase their immersive factor.&lt;/p&gt;

</description>
        <pubDate>Tue, 05 Apr 2016 09:01:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2016/04/05/Working-with-noise.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2016/04/05/Working-with-noise.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>Uberisation</title>
        <description>&lt;p&gt;Many stories and paths were crossing this week in SF and around. After many trips to this area I had the chance, this time, to experience a bit more what will it be if I was living there. Personnaly I think that you get to know a place when you start to understand how people move in their living envirronment, when they commute to work, go shopping or having some social activities.&lt;/p&gt;

&lt;p&gt;I didn’t rent a car, again. A European reflex pushing me to use the local public transport. One thing you have to recognize is that the public transport isn’t very big in the US, except a few cities, but it’s pretty cheap and there isn’t so many real cities. So pretty soon you facing the dilema &lt;em&gt;I should have rented a car&lt;/em&gt;… Being in the Bay I thought why not trying &lt;a href=&quot;https://www.uber.com/&quot;&gt;uber&lt;/a&gt;? Asking people around uber or &lt;a href=&quot;https://www.lyft.com/&quot;&gt;lyft&lt;/a&gt; were coming first, the word taxi rarely mentioned and public transport always bringing an astonished face as reaction, like why will you do that, we are not in the third world country here or something like that. Therefore I tried, and needless to say it’s super convenient.&lt;/p&gt;

&lt;p&gt;But why is it working so well here and struggling a bit let says in Paris and Berlin? I also had the chance to meet employees from uber and we were discussing about these facts. One thing interesting here is the very low public transport offer and the reaction from the big companies in the Bay to create their own public transport… It’s very convenient for them as their employees can work more, right from the commute time. Also I heard that the bus and subway lines stop earlier than in NY, Paris or Berlin, so you will have to think of your transport before going out, it’s annoying, and the taxi drivers, I heard, because being in situtation of monopole could be picky when you requested a drive.&lt;/p&gt;

&lt;p&gt;All this uber-like companies are a treat for all work closed market or semi-old monopole companies. Especially when the targeted customers aren’t happy about the service adn dependant of this monopole. Ah lovely RER train drivers…&lt;/p&gt;

&lt;p&gt;I have the feeling the only improvement comes from offering a better service, nothing really new is brought, a kind a super fancy re-packaging. If you take Apple, they were rarely the first with their new products, but something different was added. Tesla is re-doing cars. When one company is attracting suddenly all the sun to itself, then the others start to be innovative again. Uber is not completely there in Berlin or Paris, since their offensive approach in Europe behaving in a typical American way, they manage to make the locals to react, at least it’s more convenient to order a taxi on your phone in Berlin right now. A bit of fear and the things move.&lt;/p&gt;

&lt;p&gt;And the last funny observation for is the abitlity to re-invet the wheel by tech companies. It’s possible to share your uber/lyft ride with other passangers, something between a bus and taxi. Something very similar to the aluguers in Capo Verde.&lt;/p&gt;

</description>
        <pubDate>Sat, 19 Mar 2016 17:25:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2016/03/19/Ubersitation.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2016/03/19/Ubersitation.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
      <item>
        <title>From IRL to VR</title>
        <description>&lt;p&gt;I’m working on a workshop proposal for the next &lt;a href=&quot;https://www.imaging.org/site/IST/Conferences/Color_and_Imaging/IST/Conferences/CIC/CIC_Home.aspx?hkey=d2cf3f19-87b4-4164-8274-c40180e9dfa7&quot;&gt;Color Imaging Conference&lt;/a&gt; November 7-11 in San Diego CA. The topic I want to discuss with the speakers and audience is VR. The idea is to present the state of the art of research - what’s happening in the labs - and how this technology is spread to the mass - from digital dome to VR headset.&lt;/p&gt;

&lt;p&gt;The acceptance of a new technology can be reach if normal users can embrace it. It’s a challenge for all scientists, engineers, interaction designers to give easy access to often very complicated stuffs. By complicated stuff here I mean the production of an immersive movie with one or several cameras. The 360 degrees VR photography scene is almost established (see the photographer work of &lt;a href=&quot;http://tanjabarnes.com/&quot;&gt;tanjabarnes&lt;/a&gt; and thanks to software tools such as &lt;a href=&quot;http://hugin.sourceforge.net/&quot;&gt;hugin&lt;/a&gt;) one person &lt;em&gt;alone&lt;/em&gt; can produce beautiful images. For immersive movies more resources are usually needed, digital dome and planetarium such as the &lt;a href=&quot;http://www.calacademy.org/incoming-trailer&quot;&gt;California Academy of Science&lt;/a&gt; have the team to create amazing contents for the visitors attending their shows.&lt;/p&gt;

&lt;p&gt;I do think there is still a gap for people to create CGI content by themself, even so &lt;a href=&quot;https://minecraft.net/&quot;&gt;minecraft&lt;/a&gt; or &lt;a href=&quot;https://www.buildwithchrome.com/builder&quot;&gt;lego with Chrome&lt;/a&gt; are contradicting me. But if you work already in a Virtual environment you eliminate many of the drawbacks usually present to generate multi-directional views: if you know where the objects in your scene are located, without talking about quality of rendering it’s &lt;em&gt;easy&lt;/em&gt; to generate views from virtual camera at various locations in space. So far I’m only describing techonological challenges and I’m not even tackling the story telling challenges in VR. To contradict me again, the people in the game industry didn’t wait for me to tell story within a virtual envirronment.&lt;/p&gt;

&lt;h3 id=&quot;a-few-words-about-my-background&quot;&gt;A few words about my background&lt;/h3&gt;
&lt;p&gt;I’m a &lt;a href=&quot;https://de.linkedin.com/in/jeremiegerhardt&quot;&gt;color scientist&lt;/a&gt;, but over the almost last 10 years I have been involved in various VR projects regarding image quality, stichting, camera and projector calibration. Projects being the technology behind immersive displays and more specifically how to control several displays for the projection on curved surfaces. An immersirve display can be a cave, cylinder to a full sphere in that matter.&lt;/p&gt;

&lt;p&gt;I had the chance to meet different communities, one of them being the &lt;a href=&quot;http://www.imersa.org/&quot;&gt;digital dome community&lt;/a&gt;. Interesting fact for me is that these people are usually understanding/developping their technology to be able to create immersive contents for the digital domes. Another aspect I find very interesting about VR, it is now somehow easier to &lt;a href=&quot;http://www.theverge.com/2016/3/14/11206552/vr-oculus-rift-htv-vive-valve-sony-psvr-GDC&quot;&gt;consume VR content&lt;/a&gt; &lt;em&gt;alone&lt;/em&gt; with your &lt;a href=&quot;https://www.oculus.com/&quot;&gt;smartphone&lt;/a&gt; when digital dome offer a &lt;em&gt;group&lt;/em&gt; immersive experience which is pretty cool too.&lt;/p&gt;

&lt;h3 id=&quot;description-of-the-workshop-draft&quot;&gt;Description of the workshop (draft)&lt;/h3&gt;

&lt;p&gt;The recent blossoming of VR headset has open the VR doors to new users. The technology is not anymore reserved to flight simulator, research center or high end gaming console. It is now relatively easy to consume VR content on the mobile display of your smartphone equipped with a &lt;a href=&quot;https://www.google.com/get/cardboard/&quot;&gt;google Cardboard&lt;/a&gt; in the most simple case.&lt;/p&gt;

&lt;p&gt;In that workshop we want to explore the different factors leading the user to have a successful VR experience. More specifically we will look at the solution existing for creating panorama to spherical movies using several cameras or using a single acquisition device, investigate the different scenario for live contents to recorded movies.&lt;/p&gt;

&lt;p&gt;The usual approach to create panorama movie is to combine several different fields of view, the operation of stitching will allow to blend each image into a single frame. This process have to deal with hdr/tone mapping, the choice of algorithm modify the final image quality which influence the perceived feeling of immersion.&lt;/p&gt;

&lt;p&gt;The general concept with immersive video is to consider the user in the middle of a sphere where the inner surface is the content of a frame. One aspect is to give the user the possibility to change its viewing direction by simply turning his head, a second aspect is to have the content ready at each frame. It’s possible to view immersive video on a regular video player where the viewing direction can be modified with a mouse (Youtube has this option), on the other side apps for VR headset will often use gaming tools (such as &lt;a href=&quot;https://unity3d.com/&quot;&gt;Unity Game engine&lt;/a&gt;), rendering tools (openGL…) to control the environment. From that point of view, app developers can work easily with texture, camera matrix projection, stitching functions…&lt;/p&gt;

&lt;h4 id=&quot;content-filmed-with-camera-cluster&quot;&gt;Content filmed with camera cluster&lt;/h4&gt;
&lt;p&gt;It is possible to combine several action cameras with a mounting rig, see &lt;a href=&quot;http://www.360heros.com/&quot;&gt;GoPro&lt;/a&gt;. As each camera position is fixed, only one configuration file is required to stitch automatically the images, see the &lt;a href=&quot;http://www.hhi.fraunhofer.de/departments/vision-imaging-technologies/products-technologies/capture/panoramic-uhd-video.html&quot;&gt;panoramic UHD video&lt;/a&gt; from &lt;a href=&quot;http://www.hhi.fraunhofer.de/start-page.html&quot;&gt;HHI&lt;/a&gt; in Berlin. Live streaming is possible, final quality is linked to the bandwidth, how fast can tone mapping be applied, how synchronized are the different camera streams (&lt;a href=&quot;http://www.video-stitch.com/&quot;&gt;Video-Stitch&lt;/a&gt;, &lt;a href=&quot;http://www.kolor.com/&quot;&gt;Kolor&lt;/a&gt; softwares can help). With this kind of installation ghosting effect can still be visible when an object is getting too close to the camera cluster and appear in only one camera field of view.&lt;/p&gt;

&lt;h4 id=&quot;content-filmed-with-a-single-camera-on-the-fly&quot;&gt;Content filmed with a single camera on the fly&lt;/h4&gt;
&lt;p&gt;It is possible if you can always consider your camera being located in the center of a sphere. Now giving the opportunity to the user to create himself with a single device an immersive movie is really interesting because it’s an invitation for him to take control on such new media/way of expression. And the challenges for the scientists and engineers to please the future immersive video directors are numerous as the users don’t really care about the science, it should work when you press the button (who knows about automatic white balance, autofocus, hdr, 3D, face detection, noise reduction, automatic quality improvement, photography in low light…). The challenge with a single camera is to able to follow the camera movement and to provide to the app this information under the form of a rotation matrix to process stitching in real time (&lt;a href=&quot;https://www.splashapp.co/&quot;&gt;viorama and splash&lt;/a&gt; can help).&lt;/p&gt;

&lt;h3 id=&quot;expected-outcome&quot;&gt;Expected outcome&lt;/h3&gt;

&lt;p&gt;The people attending the workshop should gain knowledge about the imaging workflow for VR application using their smartphone as display: what are the key points and challenges from applied research to production.&lt;/p&gt;

&lt;h3 id=&quot;how-to-participate&quot;&gt;How to participate?&lt;/h3&gt;

&lt;p&gt;Regarding the participation to the workshop as one of the speakers to share your experience regarding the challenges listed, 
please contact me jeremie[point]gerhardt[at]gmail[point]com .&lt;/p&gt;

&lt;p&gt;Check the conference webpage &lt;a href=&quot;https://www.imaging.org/site/IST/Conferences/Color_and_Imaging/IST/Conferences/CIC/CIC_Home.aspx?hkey=d2cf3f19-87b4-4164-8274-c40180e9dfa7&quot;&gt;Color Imaging Conference&lt;/a&gt; where there is much more to discover than the few lines above.&lt;/p&gt;

</description>
        <pubDate>Tue, 15 Mar 2016 05:25:06 -0400</pubDate>
        <link>http://localhost:4000/blog/post/2016/03/15/From-IRL-to-VR.html</link>
        <guid isPermaLink="true">http://localhost:4000/blog/post/2016/03/15/From-IRL-to-VR.html</guid>
        
        
        <category>blog</category>
        
        <category>post</category>
        
      </item>
    
  </channel>
</rss>
